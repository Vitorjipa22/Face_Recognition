{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3260a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import svm\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "faa88b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(model_name, valY, yhat_val):\n",
    "    \n",
    "    cm = confusion_matrix(valY, yhat_val)\n",
    "    fig, ax = plot_confusion_matrix(conf_mat = cm , figsize=(5,5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6126b5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.028100</td>\n",
       "      <td>1.874009</td>\n",
       "      <td>0.975083</td>\n",
       "      <td>0.602640</td>\n",
       "      <td>0.651621</td>\n",
       "      <td>0.387701</td>\n",
       "      <td>0.754534</td>\n",
       "      <td>0.255482</td>\n",
       "      <td>0.570138</td>\n",
       "      <td>0.232678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>-1.750562</td>\n",
       "      <td>-0.740965</td>\n",
       "      <td>-1.333565</td>\n",
       "      <td>0.424362</td>\n",
       "      <td>1.464125</td>\n",
       "      <td>0.441541</td>\n",
       "      <td>0.117519</td>\n",
       "      <td>0.773804</td>\n",
       "      <td>desconhecidos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.281798</td>\n",
       "      <td>0.222542</td>\n",
       "      <td>-0.637775</td>\n",
       "      <td>-1.389234</td>\n",
       "      <td>-0.944202</td>\n",
       "      <td>1.170996</td>\n",
       "      <td>-2.149016</td>\n",
       "      <td>0.207373</td>\n",
       "      <td>1.258633</td>\n",
       "      <td>1.118211</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.077074</td>\n",
       "      <td>0.061272</td>\n",
       "      <td>0.858069</td>\n",
       "      <td>-0.620240</td>\n",
       "      <td>-0.448047</td>\n",
       "      <td>0.659153</td>\n",
       "      <td>-0.578539</td>\n",
       "      <td>0.022662</td>\n",
       "      <td>-1.110149</td>\n",
       "      <td>desconhecidos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.469598</td>\n",
       "      <td>-0.438383</td>\n",
       "      <td>1.035088</td>\n",
       "      <td>0.419017</td>\n",
       "      <td>-2.502093</td>\n",
       "      <td>1.199449</td>\n",
       "      <td>1.220177</td>\n",
       "      <td>-0.849276</td>\n",
       "      <td>-2.125674</td>\n",
       "      <td>0.487827</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075716</td>\n",
       "      <td>-0.870743</td>\n",
       "      <td>-0.749646</td>\n",
       "      <td>-0.024553</td>\n",
       "      <td>0.895486</td>\n",
       "      <td>-0.095862</td>\n",
       "      <td>1.756820</td>\n",
       "      <td>-0.284382</td>\n",
       "      <td>1.243302</td>\n",
       "      <td>desconhecidos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.019212</td>\n",
       "      <td>0.063674</td>\n",
       "      <td>0.368226</td>\n",
       "      <td>-0.734526</td>\n",
       "      <td>-1.221279</td>\n",
       "      <td>-1.026126</td>\n",
       "      <td>2.541132</td>\n",
       "      <td>-0.602338</td>\n",
       "      <td>0.804724</td>\n",
       "      <td>-1.249530</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.705541</td>\n",
       "      <td>1.118912</td>\n",
       "      <td>0.027196</td>\n",
       "      <td>0.776124</td>\n",
       "      <td>0.068407</td>\n",
       "      <td>-0.755236</td>\n",
       "      <td>-0.928870</td>\n",
       "      <td>-2.261591</td>\n",
       "      <td>-1.204839</td>\n",
       "      <td>desconhecidos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.792076</td>\n",
       "      <td>-1.098803</td>\n",
       "      <td>-1.363440</td>\n",
       "      <td>-0.442606</td>\n",
       "      <td>-1.206599</td>\n",
       "      <td>0.595012</td>\n",
       "      <td>-0.013578</td>\n",
       "      <td>0.476706</td>\n",
       "      <td>-1.628913</td>\n",
       "      <td>-0.248366</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.437911</td>\n",
       "      <td>0.343600</td>\n",
       "      <td>1.075108</td>\n",
       "      <td>0.339993</td>\n",
       "      <td>0.843487</td>\n",
       "      <td>0.041740</td>\n",
       "      <td>1.926534</td>\n",
       "      <td>-0.437672</td>\n",
       "      <td>0.653635</td>\n",
       "      <td>desconhecidos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.028100  1.874009  0.975083  0.602640  0.651621  0.387701  0.754534   \n",
       "1  0.281798  0.222542 -0.637775 -1.389234 -0.944202  1.170996 -2.149016   \n",
       "2 -0.469598 -0.438383  1.035088  0.419017 -2.502093  1.199449  1.220177   \n",
       "3 -0.019212  0.063674  0.368226 -0.734526 -1.221279 -1.026126  2.541132   \n",
       "4  0.792076 -1.098803 -1.363440 -0.442606 -1.206599  0.595012 -0.013578   \n",
       "\n",
       "          7         8         9  ...       119       120       121       122  \\\n",
       "0  0.255482  0.570138  0.232678  ...  0.000564 -1.750562 -0.740965 -1.333565   \n",
       "1  0.207373  1.258633  1.118211  ... -2.077074  0.061272  0.858069 -0.620240   \n",
       "2 -0.849276 -2.125674  0.487827  ... -0.075716 -0.870743 -0.749646 -0.024553   \n",
       "3 -0.602338  0.804724 -1.249530  ... -1.705541  1.118912  0.027196  0.776124   \n",
       "4  0.476706 -1.628913 -0.248366  ... -1.437911  0.343600  1.075108  0.339993   \n",
       "\n",
       "        123       124       125       126       127         target  \n",
       "0  0.424362  1.464125  0.441541  0.117519  0.773804  desconhecidos  \n",
       "1 -0.448047  0.659153 -0.578539  0.022662 -1.110149  desconhecidos  \n",
       "2  0.895486 -0.095862  1.756820 -0.284382  1.243302  desconhecidos  \n",
       "3  0.068407 -0.755236 -0.928870 -2.261591 -1.204839  desconhecidos  \n",
       "4  0.843487  0.041740  1.926534 -0.437672  0.653635  desconhecidos  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desconhecidos = pd.read_csv(\"faces_desconhecidos.csv\") \n",
    "df_desconhecidos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9ddc86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.624656</td>\n",
       "      <td>-0.447745</td>\n",
       "      <td>0.624376</td>\n",
       "      <td>0.168215</td>\n",
       "      <td>-1.183529</td>\n",
       "      <td>1.161336</td>\n",
       "      <td>1.180575</td>\n",
       "      <td>-1.458736</td>\n",
       "      <td>0.925821</td>\n",
       "      <td>0.236734</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.062742</td>\n",
       "      <td>0.596569</td>\n",
       "      <td>0.682379</td>\n",
       "      <td>0.292868</td>\n",
       "      <td>0.409854</td>\n",
       "      <td>1.634237</td>\n",
       "      <td>0.249691</td>\n",
       "      <td>-0.189478</td>\n",
       "      <td>-1.783221</td>\n",
       "      <td>glauciane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.921183</td>\n",
       "      <td>-0.228285</td>\n",
       "      <td>1.023043</td>\n",
       "      <td>-0.362588</td>\n",
       "      <td>-0.759581</td>\n",
       "      <td>0.905878</td>\n",
       "      <td>1.626263</td>\n",
       "      <td>-1.420151</td>\n",
       "      <td>1.193603</td>\n",
       "      <td>0.791741</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.375485</td>\n",
       "      <td>0.683259</td>\n",
       "      <td>0.827911</td>\n",
       "      <td>-0.167854</td>\n",
       "      <td>0.260004</td>\n",
       "      <td>1.484647</td>\n",
       "      <td>0.228390</td>\n",
       "      <td>-0.471342</td>\n",
       "      <td>-1.681182</td>\n",
       "      <td>glauciane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.037906</td>\n",
       "      <td>-0.927606</td>\n",
       "      <td>0.960223</td>\n",
       "      <td>0.052220</td>\n",
       "      <td>-1.199638</td>\n",
       "      <td>0.768999</td>\n",
       "      <td>1.396971</td>\n",
       "      <td>-0.688852</td>\n",
       "      <td>0.781067</td>\n",
       "      <td>0.692422</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.764692</td>\n",
       "      <td>0.959367</td>\n",
       "      <td>0.720395</td>\n",
       "      <td>-0.322032</td>\n",
       "      <td>0.306745</td>\n",
       "      <td>1.598800</td>\n",
       "      <td>-0.141811</td>\n",
       "      <td>-0.795695</td>\n",
       "      <td>-1.841082</td>\n",
       "      <td>glauciane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.677615</td>\n",
       "      <td>-0.018155</td>\n",
       "      <td>0.723042</td>\n",
       "      <td>-0.119465</td>\n",
       "      <td>-1.317164</td>\n",
       "      <td>1.009346</td>\n",
       "      <td>1.103884</td>\n",
       "      <td>-1.569089</td>\n",
       "      <td>0.324309</td>\n",
       "      <td>0.405659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.621289</td>\n",
       "      <td>0.506900</td>\n",
       "      <td>0.757364</td>\n",
       "      <td>0.247419</td>\n",
       "      <td>0.131484</td>\n",
       "      <td>1.497606</td>\n",
       "      <td>0.284347</td>\n",
       "      <td>-0.406723</td>\n",
       "      <td>-2.066759</td>\n",
       "      <td>glauciane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.841432</td>\n",
       "      <td>-0.305600</td>\n",
       "      <td>0.955496</td>\n",
       "      <td>-0.508191</td>\n",
       "      <td>-0.417205</td>\n",
       "      <td>1.673414</td>\n",
       "      <td>0.809553</td>\n",
       "      <td>-1.041964</td>\n",
       "      <td>1.069607</td>\n",
       "      <td>0.473020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.451649</td>\n",
       "      <td>0.114553</td>\n",
       "      <td>0.892378</td>\n",
       "      <td>0.363496</td>\n",
       "      <td>0.414226</td>\n",
       "      <td>2.106771</td>\n",
       "      <td>-0.339435</td>\n",
       "      <td>-0.562916</td>\n",
       "      <td>-2.133557</td>\n",
       "      <td>glauciane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.624656 -0.447745  0.624376  0.168215 -1.183529  1.161336  1.180575   \n",
       "1  0.921183 -0.228285  1.023043 -0.362588 -0.759581  0.905878  1.626263   \n",
       "2 -0.037906 -0.927606  0.960223  0.052220 -1.199638  0.768999  1.396971   \n",
       "3  0.677615 -0.018155  0.723042 -0.119465 -1.317164  1.009346  1.103884   \n",
       "4  0.841432 -0.305600  0.955496 -0.508191 -0.417205  1.673414  0.809553   \n",
       "\n",
       "          7         8         9  ...       119       120       121       122  \\\n",
       "0 -1.458736  0.925821  0.236734  ... -1.062742  0.596569  0.682379  0.292868   \n",
       "1 -1.420151  1.193603  0.791741  ... -1.375485  0.683259  0.827911 -0.167854   \n",
       "2 -0.688852  0.781067  0.692422  ... -1.764692  0.959367  0.720395 -0.322032   \n",
       "3 -1.569089  0.324309  0.405659  ... -0.621289  0.506900  0.757364  0.247419   \n",
       "4 -1.041964  1.069607  0.473020  ... -0.451649  0.114553  0.892378  0.363496   \n",
       "\n",
       "        123       124       125       126       127     target  \n",
       "0  0.409854  1.634237  0.249691 -0.189478 -1.783221  glauciane  \n",
       "1  0.260004  1.484647  0.228390 -0.471342 -1.681182  glauciane  \n",
       "2  0.306745  1.598800 -0.141811 -0.795695 -1.841082  glauciane  \n",
       "3  0.131484  1.497606  0.284347 -0.406723 -2.066759  glauciane  \n",
       "4  0.414226  2.106771 -0.339435 -0.562916 -2.133557  glauciane  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_conhecidos = pd.read_csv(\"faces.csv\")\n",
    "df_conhecidos.drop(\"Unnamed: 0\", axis=1, inplace = True)\n",
    "df_conhecidos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7462ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_conhecidos, df_desconhecidos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4d92f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29517, 128)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(df.drop([\"target\"], axis=1))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23e12d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29517,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(df.target)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff4b73bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anino', 'desconhecidos', 'glauciane', 'steferson'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX, trainY = shuffle(X, y, random_state = 0) # misturando tudo \n",
    "np.unique(trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96370c21",
   "metadata": {},
   "source": [
    "## TRATANDO AS LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00433e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_encoder = LabelEncoder() # enumerando as saidas\n",
    "out_encoder.fit(trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f3aedd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY = out_encoder.transform(trainY)\n",
    "np.unique(trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae0203f",
   "metadata": {},
   "source": [
    "## IMPORTANDO DADOS DE VALIDAÃ‡ÃƒO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eae4439a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anino', 'glauciane', 'steferson'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.read_csv(\"faces_validation.csv\")\n",
    "df_val = df_val.drop('Unnamed: 0', axis=1)\n",
    "np.unique(df_val.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f375bf",
   "metadata": {},
   "source": [
    "## PREPARANDO VARIAVEIS DE VALIDAÃ‡ÃƒO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8262721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valX = np.array(df_val.drop(\"target\", axis = 1))\n",
    "valY = np.array(df_val.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99c6b30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glauciane' 'anino' 'steferson' 'desconhecidos']\n"
     ]
    }
   ],
   "source": [
    "print(df.target.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4358c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_encoder.fit(valY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b04c975",
   "metadata": {},
   "outputs": [],
   "source": [
    "valY = out_encoder.transform(valY)\n",
    "# valY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b3d849",
   "metadata": {},
   "source": [
    "### KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c5d9086",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = to_categorical(trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eee3794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valY = to_categorical(valY)\n",
    "# valY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b7dcdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,516\n",
      "Trainable params: 8,516\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation = 'relu', input_shape = (128,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(4, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c2d04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss= \"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "436773ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3690/3690 [==============================] - 4s 933us/step - loss: 0.0347 - accuracy: 0.9898\n",
      "Epoch 2/100\n",
      "3690/3690 [==============================] - 3s 916us/step - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 3/100\n",
      "3690/3690 [==============================] - 3s 948us/step - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 4/100\n",
      "3690/3690 [==============================] - 3s 930us/step - loss: 7.3898e-04 - accuracy: 0.9998\n",
      "Epoch 5/100\n",
      "3690/3690 [==============================] - 3s 944us/step - loss: 8.6544e-04 - accuracy: 0.9996\n",
      "Epoch 6/100\n",
      "3690/3690 [==============================] - 4s 950us/step - loss: 6.9673e-04 - accuracy: 0.9998\n",
      "Epoch 7/100\n",
      "3690/3690 [==============================] - 4s 963us/step - loss: 2.6115e-04 - accuracy: 0.9999\n",
      "Epoch 8/100\n",
      "3690/3690 [==============================] - 3s 936us/step - loss: 4.2026e-04 - accuracy: 0.9998\n",
      "Epoch 9/100\n",
      "3690/3690 [==============================] - 3s 931us/step - loss: 1.3647e-04 - accuracy: 0.9999\n",
      "Epoch 10/100\n",
      "3690/3690 [==============================] - 3s 917us/step - loss: 2.4597e-04 - accuracy: 0.9999\n",
      "Epoch 11/100\n",
      "3690/3690 [==============================] - 3s 932us/step - loss: 5.5873e-04 - accuracy: 0.9998\n",
      "Epoch 12/100\n",
      "3690/3690 [==============================] - 4s 967us/step - loss: 5.8307e-04 - accuracy: 0.9999\n",
      "Epoch 13/100\n",
      "3690/3690 [==============================] - 4s 956us/step - loss: 1.5941e-04 - accuracy: 0.9999\n",
      "Epoch 14/100\n",
      "3690/3690 [==============================] - 3s 945us/step - loss: 5.0209e-04 - accuracy: 0.9998\n",
      "Epoch 15/100\n",
      "3690/3690 [==============================] - 3s 922us/step - loss: 1.8647e-04 - accuracy: 0.9999\n",
      "Epoch 16/100\n",
      "3690/3690 [==============================] - 3s 930us/step - loss: 2.7353e-04 - accuracy: 0.9999\n",
      "Epoch 17/100\n",
      "3690/3690 [==============================] - 4s 949us/step - loss: 5.6488e-04 - accuracy: 0.9998\n",
      "Epoch 18/100\n",
      "3690/3690 [==============================] - 3s 930us/step - loss: 1.0215e-04 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "3690/3690 [==============================] - 4s 976us/step - loss: 1.0880e-04 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "3690/3690 [==============================] - 4s 950us/step - loss: 8.1145e-06 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "3690/3690 [==============================] - 3s 941us/step - loss: 2.3107e-04 - accuracy: 0.9999\n",
      "Epoch 22/100\n",
      "3690/3690 [==============================] - 3s 929us/step - loss: 1.2188e-04 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "3690/3690 [==============================] - 3s 930us/step - loss: 2.8762e-04 - accuracy: 0.9999\n",
      "Epoch 24/100\n",
      "3690/3690 [==============================] - 3s 875us/step - loss: 1.9020e-04 - accuracy: 0.9999\n",
      "Epoch 25/100\n",
      "3690/3690 [==============================] - 3s 902us/step - loss: 1.2712e-04 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "3690/3690 [==============================] - 4s 959us/step - loss: 3.0842e-04 - accuracy: 0.9999\n",
      "Epoch 27/100\n",
      "3690/3690 [==============================] - 3s 902us/step - loss: 2.0370e-04 - accuracy: 0.9999\n",
      "Epoch 28/100\n",
      "3690/3690 [==============================] - 3s 908us/step - loss: 1.2717e-04 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "3690/3690 [==============================] - 3s 894us/step - loss: 3.6210e-04 - accuracy: 0.9998\n",
      "Epoch 30/100\n",
      "3690/3690 [==============================] - 3s 887us/step - loss: 2.1854e-04 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "3690/3690 [==============================] - 3s 931us/step - loss: 3.9307e-05 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "3690/3690 [==============================] - 3s 891us/step - loss: 3.1597e-04 - accuracy: 0.9999\n",
      "Epoch 33/100\n",
      "3690/3690 [==============================] - 3s 918us/step - loss: 5.6141e-05 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "3690/3690 [==============================] - 3s 917us/step - loss: 1.4009e-04 - accuracy: 0.9999\n",
      "Epoch 35/100\n",
      "3690/3690 [==============================] - 3s 915us/step - loss: 1.9547e-04 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "3690/3690 [==============================] - 3s 889us/step - loss: 1.3260e-05 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "3690/3690 [==============================] - 3s 890us/step - loss: 4.1128e-05 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "3690/3690 [==============================] - 3s 892us/step - loss: 2.8256e-05 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "3690/3690 [==============================] - 3s 893us/step - loss: 1.0538e-04 - accuracy: 0.9999\n",
      "Epoch 40/100\n",
      "3690/3690 [==============================] - 3s 947us/step - loss: 1.8566e-04 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "3690/3690 [==============================] - 3s 910us/step - loss: 7.6750e-05 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "3690/3690 [==============================] - 3s 869us/step - loss: 6.3750e-04 - accuracy: 0.9999\n",
      "Epoch 43/100\n",
      "3690/3690 [==============================] - 3s 868us/step - loss: 5.5693e-04 - accuracy: 0.9999\n",
      "Epoch 44/100\n",
      "3690/3690 [==============================] - 3s 863us/step - loss: 5.7968e-04 - accuracy: 0.9998\n",
      "Epoch 45/100\n",
      "3690/3690 [==============================] - 3s 895us/step - loss: 6.2643e-05 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3690/3690 [==============================] - 3s 885us/step - loss: 3.4895e-05 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "3690/3690 [==============================] - 3s 929us/step - loss: 7.6195e-05 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "3690/3690 [==============================] - 3s 906us/step - loss: 2.8818e-06 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "3690/3690 [==============================] - 3s 908us/step - loss: 5.6285e-05 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "3690/3690 [==============================] - 3s 916us/step - loss: 9.8937e-05 - accuracy: 0.9999\n",
      "Epoch 51/100\n",
      "3690/3690 [==============================] - 3s 898us/step - loss: 8.1186e-05 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "3690/3690 [==============================] - 3s 893us/step - loss: 9.8605e-05 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "3690/3690 [==============================] - 3s 892us/step - loss: 8.3058e-06 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "3690/3690 [==============================] - 3s 923us/step - loss: 1.6716e-05 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "3690/3690 [==============================] - 3s 934us/step - loss: 1.3217e-04 - accuracy: 0.9999\n",
      "Epoch 56/100\n",
      "3690/3690 [==============================] - 3s 887us/step - loss: 1.6738e-05 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "3690/3690 [==============================] - 3s 893us/step - loss: 3.5321e-04 - accuracy: 0.9999\n",
      "Epoch 58/100\n",
      "3690/3690 [==============================] - 3s 885us/step - loss: 8.7543e-05 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "3690/3690 [==============================] - 3s 891us/step - loss: 1.6858e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "3690/3690 [==============================] - 3s 912us/step - loss: 2.3211e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "3690/3690 [==============================] - 3s 920us/step - loss: 4.3960e-06 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "3690/3690 [==============================] - 3s 914us/step - loss: 1.5009e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "3690/3690 [==============================] - 3s 904us/step - loss: 1.7006e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "3690/3690 [==============================] - 3s 935us/step - loss: 1.1984e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "3690/3690 [==============================] - 3s 926us/step - loss: 8.7264e-04 - accuracy: 0.9999\n",
      "Epoch 66/100\n",
      "3690/3690 [==============================] - 3s 919us/step - loss: 1.6553e-04 - accuracy: 0.9999\n",
      "Epoch 67/100\n",
      "3690/3690 [==============================] - 3s 922us/step - loss: 2.3475e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "3690/3690 [==============================] - 4s 976us/step - loss: 1.4448e-04 - accuracy: 0.9999\n",
      "Epoch 69/100\n",
      "3690/3690 [==============================] - 4s 980us/step - loss: 1.5945e-04 - accuracy: 0.9999\n",
      "Epoch 70/100\n",
      "3690/3690 [==============================] - 4s 965us/step - loss: 2.5555e-05 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "3690/3690 [==============================] - 3s 927us/step - loss: 1.1396e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "3690/3690 [==============================] - 3s 938us/step - loss: 1.7756e-05 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "3690/3690 [==============================] - 4s 952us/step - loss: 3.2307e-05 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "3690/3690 [==============================] - 4s 967us/step - loss: 6.0242e-04 - accuracy: 0.9999\n",
      "Epoch 75/100\n",
      "3690/3690 [==============================] - 4s 969us/step - loss: 4.8052e-04 - accuracy: 0.9999\n",
      "Epoch 76/100\n",
      "3690/3690 [==============================] - 3s 943us/step - loss: 2.6067e-04 - accuracy: 0.9999\n",
      "Epoch 77/100\n",
      "3690/3690 [==============================] - 4s 949us/step - loss: 1.9485e-05 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "3690/3690 [==============================] - 4s 956us/step - loss: 1.0906e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "3690/3690 [==============================] - 3s 939us/step - loss: 4.2447e-06 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "3690/3690 [==============================] - 3s 923us/step - loss: 5.8779e-04 - accuracy: 0.9999\n",
      "Epoch 81/100\n",
      "3690/3690 [==============================] - 4s 951us/step - loss: 2.7967e-04 - accuracy: 0.9999\n",
      "Epoch 82/100\n",
      "3690/3690 [==============================] - 4s 972us/step - loss: 1.9159e-04 - accuracy: 0.9999\n",
      "Epoch 83/100\n",
      "3690/3690 [==============================] - 4s 962us/step - loss: 1.0933e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "3690/3690 [==============================] - 3s 930us/step - loss: 3.4374e-06 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "3690/3690 [==============================] - 3s 933us/step - loss: 9.4836e-07 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "3690/3690 [==============================] - 3s 939us/step - loss: 4.5563e-04 - accuracy: 0.9999\n",
      "Epoch 87/100\n",
      "3690/3690 [==============================] - 4s 950us/step - loss: 3.4864e-05 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "3690/3690 [==============================] - 4s 980us/step - loss: 9.6126e-05 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "3690/3690 [==============================] - 4s 953us/step - loss: 2.5360e-04 - accuracy: 0.9999\n",
      "Epoch 90/100\n",
      "3690/3690 [==============================] - 3s 940us/step - loss: 7.7591e-05 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "3690/3690 [==============================] - 3s 925us/step - loss: 2.6681e-04 - accuracy: 0.9999\n",
      "Epoch 92/100\n",
      "3690/3690 [==============================] - 3s 944us/step - loss: 2.3501e-06 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "3690/3690 [==============================] - 3s 928us/step - loss: 2.6830e-05 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "3690/3690 [==============================] - 3s 922us/step - loss: 1.1033e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "3690/3690 [==============================] - 3s 945us/step - loss: 7.2821e-05 - accuracy: 0.9999\n",
      "Epoch 96/100\n",
      "3690/3690 [==============================] - 3s 926us/step - loss: 1.0331e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "3690/3690 [==============================] - 3s 919us/step - loss: 8.2270e-05 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "3690/3690 [==============================] - 3s 892us/step - loss: 1.0989e-05 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "3690/3690 [==============================] - 3s 888us/step - loss: 4.2089e-04 - accuracy: 0.9999\n",
      "Epoch 100/100\n",
      "3690/3690 [==============================] - 3s 893us/step - loss: 5.9860e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e146ffc288>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=100, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f48c07b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"faces.h5\")\n",
    "model.save_weights(\"fotos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084def82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
